---
title: 'What is Linear Regression?'
date: 2018-10-11
permalink: /posts/2013/08/blog-post-2/
tags:
  - Linear Regression
  - Tutorial
  - Deep Learning
---

This is a blog post which was inspired by this [tutorial](https://www.youtube.com/watch?v=l-Fe9Ekxxj4&t=378s).

What is Linear Regression?
======
Previous blog post, we talked about general terms about artificial intelligence, machine learning, and deep learning. And this blog post will talk about linear regression because I want to share this simple example so that readers whoever want to study this concept can understand it more easily. Linear Regression is basic model that we commonly apply to our machine learning concept. I am going to briefly explain about general Linear Regression and will show a very simple example to demonstrate this model. I will use given training dataset which is presented in table 1. And this learning style is called supervised learning. I hope that people will understand and be more familiar with this linear regression model after reading this blog. I will also add some useful sources at the end of this blog so that readers can study more about this.

| Hours(x)  | Points(y)  |
| --------- | ---------- |
|    1      |     2      |
|    2      |     4      |
|    3      |     6      |
|    4      |     ?      |

**Table 1: What would be the points if we study 4 hours?**

General Explanation about Linear Regression
======
Linear Regression is the model that uses linear predictor functions to estimate unknown parameters. Perhaps this definition confuses reader more. Hence, I would like to give some concrete example that we should use linear regression model. For instance, how long should I study in order to receive good grades? I want to predict my grades depending on my time that I spent. And we assume that we have data like table 1. As we can see, we know that if we study 1 hour, we can receive 2 points, and if we study 2 hours, we will get 4 points. However, what points should we get if we study 4 hours? Fortunately, we can predict this table using linear regression model. Next paragraph will introduce the linear function that will solve this table 1. We will continue to use this table 1 as an example to demonstrate linear regression.

Definition of Linear Function
======
Usually, linear regression function forms as y = w*x+b, where y is response variable, w is random variable, x is predictor variable, and b is coefficient variable. However for the simplicity, I will drop the coefficient variable and use only y, w, and x which will form as like y = w*x. Since we defined our general function, let’s plug in the data into our function, y = w*x. As I mentioned previously, I will use same data that I created on table 1.
![](https://yunwontae.github.io/files/graph1.png)
**Figure 1:This line demonstrates correct linear function**

Demonstrating Linear Regression
======
Using Table 1, we can simply draw x and y graph. And the graph would look like figure 1. If we look at the graph, we will easily realize that when we study 4 hours, we will receive 8 points. Moreover, we can figure it out that our random variable w will be 2. This is because we used our human intelligence. Unfortunately, machine does not have this kind of human intelligence. Thus, we need to train our machine so that it can have intelligence that can solve this problem. In order to train the machine, we can simply apply random numbers to random variable.
![](https://yunwontae.github.io/files/graph2.png)
**Figure 2: Each line represents linear function**

For example, as we can see in figure 2, if we apply 1 as random variable, the line will become orange line. If we apply 3 as random variable, the line will become red line. In order to train our machine, we will use distance between blue and other lines. Since blue line is our true line that we want to find, our machine needs to find correct random variable so that it perfectly matches or closes to blue line.

How can we find random variable w?
======
As we mentioned above, we can find random variable w by minimizing the distance. Since our goal is to minimize our distance between blue line and other lines, we will use term loss, which is a distance between blue and other lines. This loss is also called as training error. To calculate the loss,we can simply use this function, (y' - y)2, where y’ represents other lines like orange and red, and y represents blue line. And because we know y' equals to x times w, we can simplify our function to (w*x -y)2.  For instance, if we use random variable 1 and plug in the data into our function, the result would be as figure 3. And we can average the loss values to find the Mean Square Error (MSE), which measures our overall errors. By looking at figure 3, we can calculate our MSE, which is 14/3. The number 14 indicates the sum of all losses and the number 3 indicates number of hours. If we keep plug in the random variable and calculate the MSE, we will eventually find where MSE is 0. And these steps are represented in figure 4. When MSE is 0 or small enough comparing to other lines, it indicates that the line is close to blue line. And this is reason why we are looking for small value of MSE.

| Hours(x)  | Points(y)  | Prediction(y')  |     Loss (w=1)    |
| --------- | ---------- | --------------  |   --------------  |
|    1      |     2      |        1        |          1        |
|    2      |     4      |        2        |          4        |
|    3      |     6      |        3        |          9        |

**Figure 3: Demonstrating Loss**

|   Hours(x)  |  Loss(w=0)  |   Loss(w=1)     |    Loss(w=2)    |  Loss(w=3)   |      Loss(w=4)    |
| :---------: | :---------: | :----------:    |  :-----------:  | :----------: |    :----------:   |
|      1      |     4       |       1         |         0       |     1        |      4            |
|      2      |     16      |       4         |         0       |     4        |      16           |
|      3      |     36      |       9         |         0       |     9        |      36           |
|            |   MSE = 56/3 |     MSE = 14/3 | MSE = 0         |   MSE = 14/3       | MSE = 56/3   |

**Figure 4: Demonstration MSE**

Conclusion
======
As we went over this linear regression model, we can simply predict the feature results. We used simple predictor function, y=w*x, to predict feature values. And we also used loss function, (y'-y)2, to find loss. When our average loss is close to zero, we could choose correct random variable, which is y=2*x. Therefore, we can predict our points when we study 4 hours. According to our predictor function, we will recieve points 8.

I hoped that this blog helped reader to understand what linear regression is and where we can apply this model to develop our machine learning. Also, I tried to simplify the problem as much as I can so that other people who do not have specific knowledge can read this blog easily. If people who want to study or know more about this linear regression model, I would recommend to read below sources.

Sources
======
[https://newonlinecourses.science.psu.edu/stat501/node/251/](https://newonlinecourses.science.psu.edu/stat501/node/251/)

This source is from PennState STAT 501, which talks about simple linear regression. It also defines each variables well. I have referenced these variable explanation to explain linear regression.

[http://www.statisticssolutions.com/what-is-linear-regression/](http://www.statisticssolutions.com/what-is-linear-regression/)

This source is from Statistics Solutions, which defines the linear regression model. This source is useful if reader wants to understand the definition of linear regression.

[https://developers.google.com/machine-learning/crash-course/descending-into-ml/linear-regression](https://developers.google.com/machine-learning/crash-course/descending-into-ml/linear-regression)

This source is from Machine Learning Crash Course, which is made by google. If anyone who wants to study more about linear regression model, I would like to recommend this open free lectures.
